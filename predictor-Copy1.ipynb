{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8844c11f-06bf-4d97-9b3e-e95d587a12c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score  # 交叉检验\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfed292-ec28-4be8-8d64-0466b9616441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '12' '15' '11' '9' '9' '16' '0' '20' '7']\n",
      " ['8' '17' '20' '0' '15' '13' '0' '0' '11' '16']\n",
      " ['17' '13' '8' '4' '11' '11' '1' '5' '7' '22']\n",
      " ['28' '16' '32' '2' '1' '6' '1' '0' '0' '14']\n",
      " ['24' '9' '0' '2' '7' '6' '5' '3' '30' '14']\n",
      " ['18' '11' '18' '0' '14' '13' '1' '2' '9' '14']\n",
      " ['4' '14' '30' '8' '5' '3' '10' '12' '1' '13']\n",
      " ['3' '18' '10' '19' '3' '10' '20' '0' '4' '13']\n",
      " ['6' '21' '8' '4' '6' '24' '0' '5' '17' '9']]\n",
      "[0 1 0 1 1 0 0 1 0]\n",
      "0.21860000000000002\n",
      "[0.395 0.255 0.07  0.64  0.26  0.2   0.525 0.745 0.44 ]\n",
      "0.2613536480992312\n",
      "0.22459152623673515\n",
      "0.4444326395583788\n",
      "0.25370097754696713\n",
      "0.25227030730544686\n",
      "mlp: 1.1640769885573115\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "fd=np.array(pd.read_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\zsy颜色统计.csv',header=None,index_col=False))\n",
    "ids=fd[1:,0]\n",
    "head=fd[0,1:]\n",
    "\n",
    "data=fd[1:,1:-5]\n",
    "labels=fd[1:,-5:]\n",
    "x_train=data[10:]\n",
    "y_train=labels[10:,3].astype(int)\n",
    "x_test=data[1:10]\n",
    "y_test=labels[1:10,3].astype(int)\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "forest.fit(x_train, y_train)\n",
    "pred = forest.predict(x_test)\n",
    "print(MSE(y_test, pred))\n",
    "print(pred)\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train, y_train)\n",
    "pred = linear.predict(x_test)\n",
    "print(MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "svm = SVR()\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "print(MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(x_train, y_train)\n",
    "pred = gbr.predict(x_test)\n",
    "print(MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "br = BayesianRidge()  # 建立贝叶斯岭回归模型对象\n",
    "br.fit(x_train, y_train)\n",
    "pred = br.predict(x_test)\n",
    "print(MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "etc = ElasticNet()  # 建立弹性网络回归模型对象\n",
    "etc.fit(x_train, y_train)\n",
    "pred = etc.predict(x_test)\n",
    "print(MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "mlp = MLPRegressor()  # 建立弹性网络回归模型对象\n",
    "mlp.fit(x_train, y_train)\n",
    "pred = mlp.predict(x_test)\n",
    "print('mlp:',MSE(y_test, pred)) \n",
    "#print(pred)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(x_train, y_train)\n",
    "pred = forest.predict(x_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79695172-940b-415c-96e1-99ed22378926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09212c91-c4a1-4099-9bbe-5d974f6062a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "#from model import ResNet, BasicBlock, Bottleneck, resnet34\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6a1ac-6613-4a54-a5ee-2142bc2bbcc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78d108b-f970-4696-ad39-1b38e5a0fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 128, 128, 3)\n",
      "(250, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "path0 = \"D:\\\\zsy\\\\image-sentiment-analysis-master\\\\image\\\\neg\\\\\"\n",
    "path1 = \"D:\\\\zsy\\\\image-sentiment-analysis-master\\\\image\\\\pos\\\\\"\n",
    "fsize=128\n",
    "\n",
    "negfiles = os.listdir(path0) \n",
    "posfiles = os.listdir(path1) \n",
    "\n",
    "neg=[]\n",
    "for i in negfiles:\n",
    "    #print(path0+i)\n",
    "    if '.jpg' in i:\n",
    "        figure=cv2.imread(path0+i)\n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        neg.append(figure)\n",
    "neglabels=[0]*len(neg) \n",
    "pos=[]\n",
    "for i in posfiles:\n",
    "    if '.jpg' in i:\n",
    "        figure=cv2.imread(path1+i)\n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        pos.append(figure)\n",
    "poslabels=[1]*len(pos)\n",
    "\n",
    "print(np.array(neg).shape)\n",
    "#print(neglabels)\n",
    "print(np.array(pos).shape)\n",
    "#print(poslabels)\n",
    "\n",
    "x_train,x_test, y_train, y_test =train_test_split(neg+pos,neglabels+poslabels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f56cd-d693-4299-81cb-902fd4464861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fac0c435-98d9-48eb-b745-bc895adce01d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "torch.Size([400, 3, 128, 128])\n",
      "torch.Size([100, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x_train).shape)\n",
    "print(np.array(x_test).shape)\n",
    "\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4f1857-c979-4df0-89f6-23b5cf56f02b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(net, X_train, Y_train,batch,epochs):\n",
    "    loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "    #optimizer = optim.Adam(resnet.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "    #logits = net(x_train)\n",
    "    #X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "    #Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "    bb=len(X_train)\n",
    "\n",
    "    resnet_loss=[]\n",
    "    for epoch in range(epochs):\n",
    "        loss_total=0\n",
    "        for b in range(bb):\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(X_train[b])\n",
    "            loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "            resnet_loss.append(loss.detach().numpy())\n",
    "            loss_total+=loss\n",
    "            loss.backward()     # 方向传播\n",
    "            optimizer.step()    # 更新优化器参数\n",
    "        print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    \n",
    "    return net, resnet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe9997-87ff-4aba-bd39-76d11b1d5ffc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b420780-f124-47ff-8034-ae0cfabb9307",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "torch.Size([400, 3, 128, 128])\n",
      "torch.Size([100, 3, 128, 128])\n",
      "epoch:0----tensor(2.3394, grad_fn=<DivBackward0>)\n",
      "epoch:1----tensor(1.5507, grad_fn=<DivBackward0>)\n",
      "epoch:2----tensor(1.2911, grad_fn=<DivBackward0>)\n",
      "epoch:3----tensor(1.2147, grad_fn=<DivBackward0>)\n",
      "epoch:4----tensor(1.1339, grad_fn=<DivBackward0>)\n",
      "epoch:5----tensor(1.0785, grad_fn=<DivBackward0>)\n",
      "epoch:6----tensor(0.9894, grad_fn=<DivBackward0>)\n",
      "epoch:7----tensor(0.9179, grad_fn=<DivBackward0>)\n",
      "epoch:8----tensor(0.8558, grad_fn=<DivBackward0>)\n",
      "epoch:9----tensor(0.7412, grad_fn=<DivBackward0>)\n",
      "epoch:10----tensor(0.5963, grad_fn=<DivBackward0>)\n",
      "epoch:11----tensor(0.5226, grad_fn=<DivBackward0>)\n",
      "epoch:12----tensor(0.5160, grad_fn=<DivBackward0>)\n",
      "epoch:13----tensor(0.3245, grad_fn=<DivBackward0>)\n",
      "epoch:14----tensor(0.3249, grad_fn=<DivBackward0>)\n",
      "epoch:15----tensor(0.2236, grad_fn=<DivBackward0>)\n",
      "epoch:16----tensor(0.2048, grad_fn=<DivBackward0>)\n",
      "epoch:17----tensor(0.0998, grad_fn=<DivBackward0>)\n",
      "epoch:18----tensor(0.1987, grad_fn=<DivBackward0>)\n",
      "epoch:19----tensor(0.1802, grad_fn=<DivBackward0>)\n",
      "epoch:20----tensor(0.1434, grad_fn=<DivBackward0>)\n",
      "epoch:21----tensor(0.5923, grad_fn=<DivBackward0>)\n",
      "epoch:22----tensor(0.2523, grad_fn=<DivBackward0>)\n",
      "epoch:23----tensor(0.1617, grad_fn=<DivBackward0>)\n",
      "epoch:24----tensor(0.1987, grad_fn=<DivBackward0>)\n",
      "epoch:25----tensor(0.0723, grad_fn=<DivBackward0>)\n",
      "epoch:26----tensor(0.0950, grad_fn=<DivBackward0>)\n",
      "epoch:27----tensor(0.1239, grad_fn=<DivBackward0>)\n",
      "epoch:28----tensor(0.1214, grad_fn=<DivBackward0>)\n",
      "epoch:29----tensor(0.0961, grad_fn=<DivBackward0>)\n",
      "epoch:30----tensor(0.0465, grad_fn=<DivBackward0>)\n",
      "epoch:31----tensor(0.0177, grad_fn=<DivBackward0>)\n",
      "epoch:32----tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "epoch:33----tensor(0.0136, grad_fn=<DivBackward0>)\n",
      "epoch:34----tensor(0.0063, grad_fn=<DivBackward0>)\n",
      "epoch:35----tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "epoch:36----tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "epoch:37----tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "epoch:38----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:39----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:40----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:41----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:42----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:43----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:44----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:45----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:46----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:47----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:48----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:49----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:50----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:51----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:52----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:53----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:54----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:55----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:56----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:57----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:58----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:59----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:60----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:61----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:62----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:63----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:64----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:65----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:66----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:67----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:68----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:69----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:70----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:71----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:72----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:73----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:74----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:75----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:76----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:77----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:78----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:79----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:80----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:81----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:82----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:83----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:84----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:85----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:86----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:87----tensor(9.8667e-05, grad_fn=<DivBackward0>)\n",
      "epoch:88----tensor(9.7249e-05, grad_fn=<DivBackward0>)\n",
      "epoch:89----tensor(9.5876e-05, grad_fn=<DivBackward0>)\n",
      "epoch:90----tensor(9.4544e-05, grad_fn=<DivBackward0>)\n",
      "epoch:91----tensor(9.3247e-05, grad_fn=<DivBackward0>)\n",
      "epoch:92----tensor(9.1995e-05, grad_fn=<DivBackward0>)\n",
      "epoch:93----tensor(9.0773e-05, grad_fn=<DivBackward0>)\n",
      "epoch:94----tensor(8.9587e-05, grad_fn=<DivBackward0>)\n",
      "epoch:95----tensor(8.8437e-05, grad_fn=<DivBackward0>)\n",
      "epoch:96----tensor(8.7314e-05, grad_fn=<DivBackward0>)\n",
      "epoch:97----tensor(8.6223e-05, grad_fn=<DivBackward0>)\n",
      "epoch:98----tensor(8.5160e-05, grad_fn=<DivBackward0>)\n",
      "epoch:99----tensor(8.4124e-05, grad_fn=<DivBackward0>)\n",
      "['1.png', '12.png', '13.png', '14.png', '16.png', '17.png', '18.png', '20.png', '21.png', '23.png', '24.png', '27.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '37.png', '38.png', '39.png', '4.png', '41.png', '42.png', '45.png', '46.png', '9.png']\n",
      "[0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "accuracy: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "#resnet50\n",
    "print(np.array(x_train).shape)\n",
    "print(np.array(x_test).shape)\n",
    "\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "#Y_train=torch.tensor(neglabels+poslabels,dtype=torch.long)\n",
    "#X_train=torch.tensor(neg+pos)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "resnet = models.resnet50(num_classes=2)\n",
    "loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.005)\n",
    "#logits = net(x_train)\n",
    "\n",
    "epochs=100\n",
    "batch=50\n",
    "X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "bb=len(X_train)\n",
    "\n",
    "resnet_loss=[]\n",
    "for epoch in range(epochs):\n",
    "    loss_total=0\n",
    "    for b in range(bb):\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet(X_train[b])\n",
    "        loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "        \n",
    "        loss_total+=loss\n",
    "        loss.backward()     # 方向传播\n",
    "        optimizer.step()    # 更新优化器参数\n",
    "    print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    resnet_loss.append(loss_total)\n",
    "\n",
    "resnet.eval()\n",
    "#outputs = resnet(X_test)\n",
    "#print(accuracy_score(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "#print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "        figure=cv2.imread('D:\\\\zsy\\\\student_model\\\\'+i)\n",
    "        \n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        figs.append(figure)\n",
    "\n",
    "infig=torch.tensor(figs)\n",
    "infig=np.transpose(infig, (0,3,1,2)).float()\n",
    "print(indexs)\n",
    "outputs = resnet(infig)\n",
    "resnet50_out=outputs\n",
    "print(np.argmax(outputs.detach().numpy(),axis=1))\n",
    "out=np.argmax(outputs.detach().numpy(),axis=1)\n",
    "\n",
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "pred_score=[]\n",
    "ss=0\n",
    "for x in range(len(indexs)):\n",
    "    if out[x]==score[indexs[x]][1]:\n",
    "            ss+=1   \n",
    "    pred_score.append([indexs[x],score[indexs[x]][1],out[x],score[indexs[x]][2],score[indexs[x]][3]])\n",
    "\n",
    "print('accuracy:',ss/len(indexs))\n",
    "pd.DataFrame(pred_score,columns=['file','label','predict','confidence','confidence_label']).to_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\result_resnet50_feature2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8e8b5d-49c6-449e-8854-c3a05358464c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        56\n",
      "           1       0.80      0.64      0.71        44\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.78      0.76      0.76       100\n",
      "weighted avg       0.77      0.77      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = resnet(X_test)\n",
    "print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4547d0b-0058-47cd-b5ec-0c4ef153bfc1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "torch.Size([400, 3, 128, 128])\n",
      "torch.Size([100, 3, 128, 128])\n",
      "epoch:0----tensor(2.1006, grad_fn=<DivBackward0>)\n",
      "epoch:1----tensor(1.6132, grad_fn=<DivBackward0>)\n",
      "epoch:2----tensor(1.6922, grad_fn=<DivBackward0>)\n",
      "epoch:3----tensor(1.6122, grad_fn=<DivBackward0>)\n",
      "epoch:4----tensor(1.4105, grad_fn=<DivBackward0>)\n",
      "epoch:5----tensor(1.0396, grad_fn=<DivBackward0>)\n",
      "epoch:6----tensor(0.9448, grad_fn=<DivBackward0>)\n",
      "epoch:7----tensor(1.0778, grad_fn=<DivBackward0>)\n",
      "epoch:8----tensor(0.8355, grad_fn=<DivBackward0>)\n",
      "epoch:9----tensor(0.8916, grad_fn=<DivBackward0>)\n",
      "epoch:10----tensor(0.8164, grad_fn=<DivBackward0>)\n",
      "epoch:11----tensor(0.7827, grad_fn=<DivBackward0>)\n",
      "epoch:12----tensor(0.6627, grad_fn=<DivBackward0>)\n",
      "epoch:13----tensor(0.5538, grad_fn=<DivBackward0>)\n",
      "epoch:14----tensor(0.6837, grad_fn=<DivBackward0>)\n",
      "epoch:15----tensor(0.3942, grad_fn=<DivBackward0>)\n",
      "epoch:16----tensor(0.3035, grad_fn=<DivBackward0>)\n",
      "epoch:17----tensor(0.5060, grad_fn=<DivBackward0>)\n",
      "epoch:18----tensor(0.5728, grad_fn=<DivBackward0>)\n",
      "epoch:19----tensor(0.3562, grad_fn=<DivBackward0>)\n",
      "epoch:20----tensor(0.5423, grad_fn=<DivBackward0>)\n",
      "epoch:21----tensor(0.2924, grad_fn=<DivBackward0>)\n",
      "epoch:22----tensor(0.4375, grad_fn=<DivBackward0>)\n",
      "epoch:23----tensor(0.2722, grad_fn=<DivBackward0>)\n",
      "epoch:24----tensor(0.3271, grad_fn=<DivBackward0>)\n",
      "epoch:25----tensor(0.2716, grad_fn=<DivBackward0>)\n",
      "epoch:26----tensor(0.1835, grad_fn=<DivBackward0>)\n",
      "epoch:27----tensor(0.0884, grad_fn=<DivBackward0>)\n",
      "epoch:28----tensor(0.0930, grad_fn=<DivBackward0>)\n",
      "epoch:29----tensor(0.1163, grad_fn=<DivBackward0>)\n",
      "epoch:30----tensor(0.1074, grad_fn=<DivBackward0>)\n",
      "epoch:31----tensor(0.1089, grad_fn=<DivBackward0>)\n",
      "epoch:32----tensor(0.1013, grad_fn=<DivBackward0>)\n",
      "epoch:33----tensor(0.0573, grad_fn=<DivBackward0>)\n",
      "epoch:34----tensor(0.0754, grad_fn=<DivBackward0>)\n",
      "epoch:35----tensor(0.0433, grad_fn=<DivBackward0>)\n",
      "epoch:36----tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "epoch:37----tensor(0.0550, grad_fn=<DivBackward0>)\n",
      "epoch:38----tensor(0.0277, grad_fn=<DivBackward0>)\n",
      "epoch:39----tensor(0.0338, grad_fn=<DivBackward0>)\n",
      "epoch:40----tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "epoch:41----tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "epoch:42----tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "epoch:43----tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "epoch:44----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:45----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:46----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:47----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:48----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:49----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:50----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:51----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:52----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:53----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:54----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:55----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:56----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:57----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:58----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:59----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:60----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:61----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:62----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:63----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:64----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:65----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:66----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:67----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:68----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:69----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:70----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:71----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:72----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:73----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:74----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:75----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:76----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:77----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:78----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:79----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:80----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:81----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:82----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:83----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:84----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:85----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:86----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:87----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:88----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:89----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:90----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:91----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:92----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:93----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:94----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:95----tensor(9.9579e-05, grad_fn=<DivBackward0>)\n",
      "epoch:96----tensor(9.8176e-05, grad_fn=<DivBackward0>)\n",
      "epoch:97----tensor(9.6813e-05, grad_fn=<DivBackward0>)\n",
      "epoch:98----tensor(9.5493e-05, grad_fn=<DivBackward0>)\n",
      "epoch:99----tensor(9.4212e-05, grad_fn=<DivBackward0>)\n",
      "0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74        56\n",
      "           1       0.67      0.64      0.65        44\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.70      0.69      0.69       100\n",
      "weighted avg       0.70      0.70      0.70       100\n",
      "\n",
      "['1.png', '12.png', '13.png', '14.png', '16.png', '17.png', '18.png', '20.png', '21.png', '23.png', '24.png', '27.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '37.png', '38.png', '39.png', '4.png', '41.png', '42.png', '45.png', '46.png', '9.png']\n",
      "[0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0]\n",
      "accuracy: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "#resnet101\n",
    "print(np.array(x_train).shape)\n",
    "print(np.array(x_test).shape)\n",
    "\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "resnet = models.resnet101(num_classes=2)\n",
    "loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.005)\n",
    "#logits = net(x_train)\n",
    "\n",
    "epochs=100\n",
    "batch=50\n",
    "X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "bb=len(X_train)\n",
    "\n",
    "resnet_loss101=[]\n",
    "for epoch in range(epochs):\n",
    "    loss_total=0\n",
    "    for b in range(bb):\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet(X_train[b])\n",
    "        loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "        \n",
    "        loss_total+=loss\n",
    "        loss.backward()     # 方向传播\n",
    "        optimizer.step()    # 更新优化器参数\n",
    "    print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    resnet_loss101.append(loss_total)\n",
    "\n",
    "resnet.eval()\n",
    "outputs = resnet(X_test)\n",
    "print(accuracy_score(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "        figure=cv2.imread('D:\\\\zsy\\\\student_model\\\\'+i)\n",
    "        \n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        figs.append(figure)\n",
    "\n",
    "infig=torch.tensor(figs)\n",
    "infig=np.transpose(infig, (0,3,1,2)).float()\n",
    "print(indexs)\n",
    "outputs = resnet(infig)\n",
    "resnet101_out=outputs\n",
    "print(np.argmax(outputs.detach().numpy(),axis=1))\n",
    "out=np.argmax(outputs.detach().numpy(),axis=1)\n",
    "\n",
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "pred_score=[]\n",
    "ss=0\n",
    "for x in range(len(indexs)):\n",
    "    if out[x]==score[indexs[x]][1]:\n",
    "            ss+=1   \n",
    "    pred_score.append([indexs[x],score[indexs[x]][1],out[x],score[indexs[x]][2],score[indexs[x]][3]])\n",
    "\n",
    "print('accuracy:',ss/len(indexs))\n",
    "pd.DataFrame(pred_score,columns=['file','label','predict','confidence','confidence_label']).to_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\result_resnet101_feature2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e215fe-4363-40d0-b59c-9138f16c99c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "torch.Size([400, 3, 128, 128])\n",
      "torch.Size([100, 3, 128, 128])\n",
      "epoch:0----tensor(1.6964, grad_fn=<DivBackward0>)\n",
      "epoch:1----tensor(1.7310, grad_fn=<DivBackward0>)\n",
      "epoch:2----tensor(1.5672, grad_fn=<DivBackward0>)\n",
      "epoch:3----tensor(1.4878, grad_fn=<DivBackward0>)\n",
      "epoch:4----tensor(1.3881, grad_fn=<DivBackward0>)\n",
      "epoch:5----tensor(1.2708, grad_fn=<DivBackward0>)\n",
      "epoch:6----tensor(1.2058, grad_fn=<DivBackward0>)\n",
      "epoch:7----tensor(1.1385, grad_fn=<DivBackward0>)\n",
      "epoch:8----tensor(1.0636, grad_fn=<DivBackward0>)\n",
      "epoch:9----tensor(1.0220, grad_fn=<DivBackward0>)\n",
      "epoch:10----tensor(0.8826, grad_fn=<DivBackward0>)\n",
      "epoch:11----tensor(0.7337, grad_fn=<DivBackward0>)\n",
      "epoch:12----tensor(0.5729, grad_fn=<DivBackward0>)\n",
      "epoch:13----tensor(0.5195, grad_fn=<DivBackward0>)\n",
      "epoch:14----tensor(0.3876, grad_fn=<DivBackward0>)\n",
      "epoch:15----tensor(0.5962, grad_fn=<DivBackward0>)\n",
      "epoch:16----tensor(0.5832, grad_fn=<DivBackward0>)\n",
      "epoch:17----tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "epoch:18----tensor(0.5729, grad_fn=<DivBackward0>)\n",
      "epoch:19----tensor(0.2796, grad_fn=<DivBackward0>)\n",
      "epoch:20----tensor(0.2977, grad_fn=<DivBackward0>)\n",
      "epoch:21----tensor(0.2509, grad_fn=<DivBackward0>)\n",
      "epoch:22----tensor(0.2338, grad_fn=<DivBackward0>)\n",
      "epoch:23----tensor(0.2560, grad_fn=<DivBackward0>)\n",
      "epoch:24----tensor(0.3056, grad_fn=<DivBackward0>)\n",
      "epoch:25----tensor(0.1772, grad_fn=<DivBackward0>)\n",
      "epoch:26----tensor(0.2046, grad_fn=<DivBackward0>)\n",
      "epoch:27----tensor(0.1702, grad_fn=<DivBackward0>)\n",
      "epoch:28----tensor(0.1552, grad_fn=<DivBackward0>)\n",
      "epoch:29----tensor(0.0961, grad_fn=<DivBackward0>)\n",
      "epoch:30----tensor(0.0650, grad_fn=<DivBackward0>)\n",
      "epoch:31----tensor(0.0458, grad_fn=<DivBackward0>)\n",
      "epoch:32----tensor(0.0414, grad_fn=<DivBackward0>)\n",
      "epoch:33----tensor(0.0669, grad_fn=<DivBackward0>)\n",
      "epoch:34----tensor(0.0328, grad_fn=<DivBackward0>)\n",
      "epoch:35----tensor(0.0312, grad_fn=<DivBackward0>)\n",
      "epoch:36----tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "epoch:37----tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "epoch:38----tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "epoch:39----tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "epoch:40----tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "epoch:41----tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "epoch:42----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:43----tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "epoch:44----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:45----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:46----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:47----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:48----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:49----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:50----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:51----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:52----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:53----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:54----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:55----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:56----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:57----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:58----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:59----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:60----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:61----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:62----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:63----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:64----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:65----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:66----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:67----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:68----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:69----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:70----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:71----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:72----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:73----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:74----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:75----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:76----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:77----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:78----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:79----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:80----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:81----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:82----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:83----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:84----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:85----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:86----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:87----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:88----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:89----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:90----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:91----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:92----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:93----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:94----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:95----tensor(9.8903e-05, grad_fn=<DivBackward0>)\n",
      "epoch:96----tensor(9.7611e-05, grad_fn=<DivBackward0>)\n",
      "epoch:97----tensor(9.6354e-05, grad_fn=<DivBackward0>)\n",
      "epoch:98----tensor(9.5127e-05, grad_fn=<DivBackward0>)\n",
      "epoch:99----tensor(9.3938e-05, grad_fn=<DivBackward0>)\n",
      "0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.69        56\n",
      "           1       0.62      0.82      0.71        44\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.72      0.71      0.70       100\n",
      "weighted avg       0.73      0.70      0.70       100\n",
      "\n",
      "['1.png', '12.png', '13.png', '14.png', '16.png', '17.png', '18.png', '20.png', '21.png', '23.png', '24.png', '27.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '37.png', '38.png', '39.png', '4.png', '41.png', '42.png', '45.png', '46.png', '9.png']\n",
      "[0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      "accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#resnet152\n",
    "print(np.array(x_train).shape)\n",
    "print(np.array(x_test).shape)\n",
    "\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "resnet = models.resnet152(num_classes=2)\n",
    "loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.005)\n",
    "#logits = net(x_train)\n",
    "\n",
    "epochs=100\n",
    "batch=50\n",
    "X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "bb=len(X_train)\n",
    "\n",
    "resnet_loss152=[]\n",
    "for epoch in range(epochs):\n",
    "    loss_total=0\n",
    "    for b in range(bb):\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet(X_train[b])\n",
    "        loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "        \n",
    "        loss_total+=loss\n",
    "        loss.backward()     # 方向传播\n",
    "        optimizer.step()    # 更新优化器参数\n",
    "    print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    resnet_loss152.append(loss_total)\n",
    "\n",
    "resnet.eval()\n",
    "outputs = resnet(X_test)\n",
    "print(accuracy_score(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "        figure=cv2.imread('D:\\\\zsy\\\\student_model\\\\'+i)\n",
    "        \n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        figs.append(figure)\n",
    "\n",
    "infig=torch.tensor(figs)\n",
    "infig=np.transpose(infig, (0,3,1,2)).float()\n",
    "print(indexs)\n",
    "outputs = resnet(infig)\n",
    "resnet152_out=outputs\n",
    "print(np.argmax(outputs.detach().numpy(),axis=1))\n",
    "out=np.argmax(outputs.detach().numpy(),axis=1)\n",
    "\n",
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "pred_score=[]\n",
    "ss=0\n",
    "for x in range(len(indexs)):\n",
    "    if out[x]==score[indexs[x]][1]:\n",
    "            ss+=1   \n",
    "    pred_score.append([indexs[x],score[indexs[x]][1],out[x],score[indexs[x]][2],score[indexs[x]][3]])\n",
    "\n",
    "print('accuracy:',ss/len(indexs))\n",
    "pd.DataFrame(pred_score,columns=['file','label','predict','confidence','confidence_label']).to_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\result_resnet152_feature2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a11cf7e7-2e02-4e3f-b536-a78b98875d5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:1----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:2----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:3----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:4----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:5----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:6----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:7----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:8----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:9----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:10----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:11----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:12----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:13----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:14----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:15----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:16----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:17----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:18----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:19----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:20----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:21----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:22----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:23----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:24----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:25----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:26----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:27----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:28----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:29----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:30----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:31----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:32----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:33----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:34----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:35----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:36----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:37----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:38----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:39----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:40----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:41----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:42----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:43----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:44----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:45----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:46----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:47----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:48----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:49----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:50----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:51----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:52----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:53----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:54----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:55----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:56----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:57----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:58----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:59----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:60----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:61----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:62----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:63----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:64----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:65----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:66----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:67----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:68----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:69----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:70----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:71----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:72----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:73----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:74----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:75----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:76----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:77----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:78----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:79----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:80----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:81----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:82----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:83----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:84----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:85----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:86----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:87----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:88----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:89----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:90----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:91----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:92----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:93----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:94----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:95----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:96----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:97----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:98----tensor(nan, grad_fn=<DivBackward0>)\n",
      "epoch:99----tensor(nan, grad_fn=<DivBackward0>)\n",
      "0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72        56\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.28      0.50      0.36       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "['1.png', '12.png', '13.png', '14.png', '16.png', '17.png', '18.png', '20.png', '21.png', '23.png', '24.png', '27.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '37.png', '38.png', '39.png', '4.png', '41.png', '42.png', '45.png', '46.png', '9.png']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "accuracy: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "#vgg\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "vgg = models.vgg16(pretrained=False)\n",
    "vgg.classifier.add_module(\"add_linear\",torch.nn.Linear(1000,2))\n",
    "loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "#optimizer = optim.Adam(vgg.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=0.005)\n",
    "#logits = net(x_train)\n",
    "\n",
    "epochs=100\n",
    "batch=50\n",
    "X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "bb=len(X_train)\n",
    "\n",
    "vgg_loss=[]\n",
    "for epoch in range(epochs):\n",
    "    loss_total=0\n",
    "    for b in range(bb):\n",
    "        optimizer.zero_grad()\n",
    "        logits = vgg(X_train[b])\n",
    "        loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "        \n",
    "        loss_total+=loss\n",
    "        loss.backward()     # 方向传播\n",
    "        optimizer.step()    # 更新优化器参数\n",
    "    print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    vgg_loss.append(loss_total)\n",
    "\n",
    "vgg.eval()\n",
    "outputs = vgg(X_test)\n",
    "print(accuracy_score(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "        figure=cv2.imread('D:\\\\zsy\\\\student_model\\\\'+i)\n",
    "        \n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        figs.append(figure)\n",
    "\n",
    "infig=torch.tensor(figs)\n",
    "infig=np.transpose(infig, (0,3,1,2)).float()\n",
    "print(indexs)\n",
    "outputs = vgg(infig)\n",
    "vgg_out=outputs\n",
    "print(np.argmax(outputs.detach().numpy(),axis=1))\n",
    "out=np.argmax(outputs.detach().numpy(),axis=1)\n",
    "\n",
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "pred_score=[]\n",
    "ss=0\n",
    "for x in range(len(indexs)):\n",
    "    if out[x]==score[indexs[x]][1]:\n",
    "            ss+=1   \n",
    "    pred_score.append([indexs[x],score[indexs[x]][1],out[x],score[indexs[x]][2],score[indexs[x]][3]])\n",
    "\n",
    "print('accuracy:',ss/len(indexs))\n",
    "pd.DataFrame(pred_score,columns=['file','label','predict','confidence','confidence_label']).to_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\result_vgg_feature2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df071a8d-e544-41d8-a222-933fe7a34885",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0----tensor(0.7801, grad_fn=<DivBackward0>)\n",
      "epoch:1----tensor(0.6816, grad_fn=<DivBackward0>)\n",
      "epoch:2----tensor(0.6615, grad_fn=<DivBackward0>)\n",
      "epoch:3----tensor(0.6350, grad_fn=<DivBackward0>)\n",
      "epoch:4----tensor(0.6380, grad_fn=<DivBackward0>)\n",
      "epoch:5----tensor(0.5894, grad_fn=<DivBackward0>)\n",
      "epoch:6----tensor(0.5635, grad_fn=<DivBackward0>)\n",
      "epoch:7----tensor(0.5467, grad_fn=<DivBackward0>)\n",
      "epoch:8----tensor(0.4971, grad_fn=<DivBackward0>)\n",
      "epoch:9----tensor(0.4859, grad_fn=<DivBackward0>)\n",
      "epoch:10----tensor(0.4356, grad_fn=<DivBackward0>)\n",
      "epoch:11----tensor(0.4041, grad_fn=<DivBackward0>)\n",
      "epoch:12----tensor(0.3631, grad_fn=<DivBackward0>)\n",
      "epoch:13----tensor(0.3749, grad_fn=<DivBackward0>)\n",
      "epoch:14----tensor(0.3311, grad_fn=<DivBackward0>)\n",
      "epoch:15----tensor(0.2465, grad_fn=<DivBackward0>)\n",
      "epoch:16----tensor(0.4197, grad_fn=<DivBackward0>)\n",
      "epoch:17----tensor(0.2965, grad_fn=<DivBackward0>)\n",
      "epoch:18----tensor(0.3650, grad_fn=<DivBackward0>)\n",
      "epoch:19----tensor(0.2536, grad_fn=<DivBackward0>)\n",
      "epoch:20----tensor(0.2797, grad_fn=<DivBackward0>)\n",
      "epoch:21----tensor(0.2056, grad_fn=<DivBackward0>)\n",
      "epoch:22----tensor(0.1598, grad_fn=<DivBackward0>)\n",
      "epoch:23----tensor(0.3708, grad_fn=<DivBackward0>)\n",
      "epoch:24----tensor(0.2096, grad_fn=<DivBackward0>)\n",
      "epoch:25----tensor(0.2097, grad_fn=<DivBackward0>)\n",
      "epoch:26----tensor(0.2991, grad_fn=<DivBackward0>)\n",
      "epoch:27----tensor(0.1712, grad_fn=<DivBackward0>)\n",
      "epoch:28----tensor(0.1236, grad_fn=<DivBackward0>)\n",
      "epoch:29----tensor(0.1977, grad_fn=<DivBackward0>)\n",
      "epoch:30----tensor(0.0242, grad_fn=<DivBackward0>)\n",
      "epoch:31----tensor(0.1670, grad_fn=<DivBackward0>)\n",
      "epoch:32----tensor(0.0807, grad_fn=<DivBackward0>)\n",
      "epoch:33----tensor(0.0207, grad_fn=<DivBackward0>)\n",
      "epoch:34----tensor(0.2521, grad_fn=<DivBackward0>)\n",
      "epoch:35----tensor(0.0688, grad_fn=<DivBackward0>)\n",
      "epoch:36----tensor(0.0259, grad_fn=<DivBackward0>)\n",
      "epoch:37----tensor(0.0370, grad_fn=<DivBackward0>)\n",
      "epoch:38----tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "epoch:39----tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "epoch:40----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:41----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:42----tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "epoch:43----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:44----tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "epoch:45----tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "epoch:46----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:47----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:48----tensor(7.5534e-05, grad_fn=<DivBackward0>)\n",
      "epoch:49----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:50----tensor(5.8817e-05, grad_fn=<DivBackward0>)\n",
      "epoch:51----tensor(6.9277e-05, grad_fn=<DivBackward0>)\n",
      "epoch:52----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:53----tensor(6.6568e-05, grad_fn=<DivBackward0>)\n",
      "epoch:54----tensor(9.6107e-05, grad_fn=<DivBackward0>)\n",
      "epoch:55----tensor(4.9955e-05, grad_fn=<DivBackward0>)\n",
      "epoch:56----tensor(4.2075e-05, grad_fn=<DivBackward0>)\n",
      "epoch:57----tensor(6.0236e-05, grad_fn=<DivBackward0>)\n",
      "epoch:58----tensor(5.7397e-05, grad_fn=<DivBackward0>)\n",
      "epoch:59----tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "epoch:60----tensor(3.4705e-05, grad_fn=<DivBackward0>)\n",
      "epoch:61----tensor(4.5769e-05, grad_fn=<DivBackward0>)\n",
      "epoch:62----tensor(4.2280e-05, grad_fn=<DivBackward0>)\n",
      "epoch:63----tensor(6.8709e-05, grad_fn=<DivBackward0>)\n",
      "epoch:64----tensor(8.5873e-05, grad_fn=<DivBackward0>)\n",
      "epoch:65----tensor(5.2505e-05, grad_fn=<DivBackward0>)\n",
      "epoch:66----tensor(3.4017e-05, grad_fn=<DivBackward0>)\n",
      "epoch:67----tensor(6.2069e-05, grad_fn=<DivBackward0>)\n",
      "epoch:68----tensor(2.6495e-05, grad_fn=<DivBackward0>)\n",
      "epoch:69----tensor(2.6272e-05, grad_fn=<DivBackward0>)\n",
      "epoch:70----tensor(4.0437e-05, grad_fn=<DivBackward0>)\n",
      "epoch:71----tensor(4.4202e-05, grad_fn=<DivBackward0>)\n",
      "epoch:72----tensor(4.9211e-05, grad_fn=<DivBackward0>)\n",
      "epoch:73----tensor(5.3163e-05, grad_fn=<DivBackward0>)\n",
      "epoch:74----tensor(3.5011e-05, grad_fn=<DivBackward0>)\n",
      "epoch:75----tensor(3.9631e-05, grad_fn=<DivBackward0>)\n",
      "epoch:76----tensor(4.3001e-05, grad_fn=<DivBackward0>)\n",
      "epoch:77----tensor(2.9121e-05, grad_fn=<DivBackward0>)\n",
      "epoch:78----tensor(3.3911e-05, grad_fn=<DivBackward0>)\n",
      "epoch:79----tensor(2.3491e-05, grad_fn=<DivBackward0>)\n",
      "epoch:80----tensor(1.8246e-05, grad_fn=<DivBackward0>)\n",
      "epoch:81----tensor(3.2966e-05, grad_fn=<DivBackward0>)\n",
      "epoch:82----tensor(3.0351e-05, grad_fn=<DivBackward0>)\n",
      "epoch:83----tensor(2.0040e-05, grad_fn=<DivBackward0>)\n",
      "epoch:84----tensor(2.4322e-05, grad_fn=<DivBackward0>)\n",
      "epoch:85----tensor(2.5036e-05, grad_fn=<DivBackward0>)\n",
      "epoch:86----tensor(2.6260e-05, grad_fn=<DivBackward0>)\n",
      "epoch:87----tensor(1.9119e-05, grad_fn=<DivBackward0>)\n",
      "epoch:88----tensor(3.4219e-05, grad_fn=<DivBackward0>)\n",
      "epoch:89----tensor(1.6646e-05, grad_fn=<DivBackward0>)\n",
      "epoch:90----tensor(2.8297e-05, grad_fn=<DivBackward0>)\n",
      "epoch:91----tensor(2.4776e-05, grad_fn=<DivBackward0>)\n",
      "epoch:92----tensor(2.3043e-05, grad_fn=<DivBackward0>)\n",
      "epoch:93----tensor(2.6194e-05, grad_fn=<DivBackward0>)\n",
      "epoch:94----tensor(1.5384e-05, grad_fn=<DivBackward0>)\n",
      "epoch:95----tensor(2.5510e-05, grad_fn=<DivBackward0>)\n",
      "epoch:96----tensor(1.6602e-05, grad_fn=<DivBackward0>)\n",
      "epoch:97----tensor(2.3996e-05, grad_fn=<DivBackward0>)\n",
      "epoch:98----tensor(1.7195e-05, grad_fn=<DivBackward0>)\n",
      "epoch:99----tensor(3.0731e-05, grad_fn=<DivBackward0>)\n",
      "0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70        56\n",
      "           1       0.62      0.75      0.68        44\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.69      0.70      0.69       100\n",
      "weighted avg       0.70      0.69      0.69       100\n",
      "\n",
      "['1.png', '12.png', '13.png', '14.png', '16.png', '17.png', '18.png', '20.png', '21.png', '23.png', '24.png', '27.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '37.png', '38.png', '39.png', '4.png', '41.png', '42.png', '45.png', '46.png', '9.png']\n",
      "[0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1]\n",
      "accuracy: 0.37037037037037035\n"
     ]
    }
   ],
   "source": [
    "#alexnet\n",
    "X_train=torch.tensor(x_train)\n",
    "Y_train=torch.tensor(y_train,dtype=torch.long)\n",
    "X_train=np.transpose(X_train, (0,3,1,2)).float()\n",
    "X_test=torch.tensor(x_test)\n",
    "Y_test=torch.tensor(y_test,dtype=torch.long)\n",
    "X_test=np.transpose(X_test, (0,3,1,2)).float()\n",
    "\n",
    "alexnet = models.alexnet(pretrained=False)\n",
    "alexnet.classifier.add_module(\"add_linear\",torch.nn.Linear(1000,2))\n",
    "loss_function = nn.CrossEntropyLoss()   # 交叉熵损失\n",
    "#optimizer = optim.Adam(alexnet.parameters(), lr=0.001)     # 优化器(训练参数, 学习率)\n",
    "optimizer = torch.optim.SGD(alexnet.parameters(), lr=0.005)\n",
    "#logits = net(x_train)\n",
    "\n",
    "epochs=100\n",
    "batch=50\n",
    "X_train=X_train[:int(len(X_train)/batch)*batch].reshape(batch,int(len(X_train)/batch),3,128,128)\n",
    "Y_train=Y_train[:int(len(Y_train)/batch)*batch].reshape(batch,int(len(Y_train)/batch))\n",
    "bb=len(X_train)\n",
    "\n",
    "alexnet_loss=[]\n",
    "for epoch in range(epochs):\n",
    "    loss_total=0\n",
    "    for b in range(bb):\n",
    "        optimizer.zero_grad()\n",
    "        logits = alexnet(X_train[b])\n",
    "        loss = loss_function(logits, Y_train[b])   # 计算损失值\n",
    "        \n",
    "        loss_total+=loss\n",
    "        loss.backward()     # 方向传播\n",
    "        optimizer.step()    # 更新优化器参数\n",
    "    print('epoch:'+str(epoch)+'----'+str(loss_total/bb))\n",
    "    alexnet_loss.append(loss_total)\n",
    "\n",
    "alexnet.eval()\n",
    "outputs = alexnet(X_test)\n",
    "print(accuracy_score(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "print(classification_report(Y_test,np.argmax(outputs.detach().numpy(),axis=1)))\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "        figure=cv2.imread('D:\\\\zsy\\\\student_model\\\\'+i)\n",
    "        \n",
    "        figure=cv2.resize(figure,(fsize,fsize))\n",
    "        #figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "        #figure=figure.reshape(fsize,fsize,1)\n",
    "        #figure = np.concatenate((figure, figure, figure), axis=-1)\n",
    "        figs.append(figure)\n",
    "\n",
    "infig=torch.tensor(figs)\n",
    "infig=np.transpose(infig, (0,3,1,2)).float()\n",
    "print(indexs)\n",
    "outputs = alexnet(infig)\n",
    "alexnet_out=outputs\n",
    "print(np.argmax(outputs.detach().numpy(),axis=1))\n",
    "out=np.argmax(outputs.detach().numpy(),axis=1)\n",
    "\n",
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "pred_score=[]\n",
    "ss=0\n",
    "for x in range(len(indexs)):\n",
    "    if out[x]==score[indexs[x]][1]:\n",
    "            ss+=1   \n",
    "    pred_score.append([indexs[x],score[indexs[x]][1],out[x],score[indexs[x]][2],score[indexs[x]][3]])\n",
    "\n",
    "print('accuracy:',ss/len(indexs))\n",
    "pd.DataFrame(pred_score,columns=['file','label','predict','confidence','confidence_label']).to_csv('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\result_alexnet_feature2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d520343-5adb-4cc1-af44-a1e1c8d7556a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5175cb-14be-4f3c-8aea-2c1d0a9276ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        17\n",
      "           1       0.44      0.40      0.42        10\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.56      0.55      0.55        27\n",
      "weighted avg       0.58      0.59      0.59        27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.53      0.62        17\n",
      "           1       0.47      0.70      0.56        10\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.61      0.61      0.59        27\n",
      "weighted avg       0.65      0.59      0.60        27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        17\n",
      "           1       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.64      0.63      0.63        27\n",
      "weighted avg       0.66      0.67      0.66        27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        17\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.31      0.50      0.39        27\n",
      "weighted avg       0.40      0.63      0.49        27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.18      0.26        17\n",
      "           1       0.33      0.70      0.45        10\n",
      "\n",
      "    accuracy                           0.37        27\n",
      "   macro avg       0.42      0.44      0.36        27\n",
      "weighted avg       0.44      0.37      0.33        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(score[i][1])\n",
    "        \n",
    "\n",
    "print(classification_report(indexs,np.argmax(resnet50_out.detach().numpy(),axis=1)))\n",
    "print(classification_report(indexs,np.argmax(resnet101_out.detach().numpy(),axis=1)))\n",
    "print(classification_report(indexs,np.argmax(resnet152_out.detach().numpy(),axis=1)))\n",
    "print(classification_report(indexs,np.argmax(vgg_out.detach().numpy(),axis=1)))\n",
    "print(classification_report(indexs,np.argmax(alexnet_out.detach().numpy(),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7891fdde-4dd1-41ba-b935-1ce251179315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        12\n",
      "           1       0.50      0.40      0.44         5\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.63      0.62      0.62        17\n",
      "weighted avg       0.69      0.71      0.70        17\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73         9\n",
      "           1       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.68      0.63      0.61        17\n",
      "weighted avg       0.68      0.65      0.62        17\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.67      0.67      0.67        17\n",
      "weighted avg       0.76      0.76      0.76        17\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.50      0.38      0.43        17\n",
      "weighted avg       1.00      0.76      0.87        17\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.75      0.35         4\n",
      "           1       0.75      0.23      0.35        13\n",
      "\n",
      "    accuracy                           0.35        17\n",
      "   macro avg       0.49      0.49      0.35        17\n",
      "weighted avg       0.63      0.35      0.35        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\55019\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fd=np.array(pd.read_csv('D:\\\\zsy\\\\zsy颜色统计.csv',index_col=False))\n",
    "score={}\n",
    "for i in fd:\n",
    "    score[str(i[0])+'.png']=[i[12],i[14],i[15],i[16]]\n",
    "\n",
    "files = os.listdir('D:\\\\zsy\\\\student_model\\\\') \n",
    "figs=[]\n",
    "indexs=[]\n",
    "for i in files:\n",
    "    if '.png' in i:\n",
    "        indexs.append(i)\n",
    "\n",
    "data=[]\n",
    "for i in range(len(indexs)):\n",
    "    if score[indexs[i]][3]==0:\n",
    "        data.append([np.argmax(resnet50_out[i].detach().numpy()),score[indexs[i]][1]])\n",
    "data=np.array(data)        \n",
    "print(classification_report(data[:,0],data[:,1]))\n",
    "\n",
    "data=[]\n",
    "for i in range(len(indexs)):\n",
    "    if score[indexs[i]][3]==0:\n",
    "        data.append([np.argmax(resnet101_out[i].detach().numpy()),score[indexs[i]][1]])\n",
    "data=np.array(data)        \n",
    "print(classification_report(data[:,0],data[:,1]))\n",
    "\n",
    "data=[]\n",
    "for i in range(len(indexs)):\n",
    "    if score[indexs[i]][3]==0:\n",
    "        data.append([np.argmax(resnet152_out[i].detach().numpy()),score[indexs[i]][1]])\n",
    "data=np.array(data)        \n",
    "print(classification_report(data[:,0],data[:,1]))\n",
    "\n",
    "data=[]\n",
    "for i in range(len(indexs)):\n",
    "    if score[indexs[i]][3]==0:\n",
    "        data.append([np.argmax(vgg_out[i].detach().numpy()),score[indexs[i]][1]])\n",
    "data=np.array(data)        \n",
    "print(classification_report(data[:,0],data[:,1]))\n",
    "\n",
    "data=[]\n",
    "for i in range(len(indexs)):\n",
    "    if score[indexs[i]][3]==0:\n",
    "        data.append([np.argmax(alexnet_out[i].detach().numpy()),score[indexs[i]][1]])\n",
    "data=np.array(data)        \n",
    "print(classification_report(data[:,0],data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e5c22-291b-488a-a702-bd4da5100537",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48826b3-5efa-4450-a737-0f5b42b9d8a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_loss(resnet_loss,resnet_loss101,resnet_loss152,vgg_loss,alexnet_loss):\n",
    "    '''for i in range(len(resnet_loss)):\n",
    "        resnet_loss[i]=resnet_loss[i].detach().numpy()\n",
    "    for i in range(len(resnet_loss101)):\n",
    "        resnet_loss101[i]=resnet_loss101[i].detach().numpy()\n",
    "    for i in range(len(resnet_loss152)):\n",
    "        resnet_loss152[i]=resnet_loss152[i].detach().numpy()\n",
    "    for i in range(len(vgg_loss)):\n",
    "        vgg_loss[i]=vgg_loss[i].detach().numpy()\n",
    "    for i in range(len(alexnet_loss)):\n",
    "        alexnet_loss[i]=alexnet_loss[i].detach().numpy()'''\n",
    "        \n",
    "    plt.figure(dpi=500)         \n",
    "    plt.title('loss during training')  #标题\n",
    "    length=range(len(alexnet_loss))\n",
    "    plt.plot(length, resnet_loss, label=\"resnet50\")\n",
    "    plt.plot(length, resnet_loss101, label=\"resnet101\")\n",
    "    plt.plot(length, resnet_loss152, label=\"resnet152\")\n",
    "    plt.plot(length, vgg_loss, label=\"vgg\")\n",
    "    plt.plot(length, alexnet_loss, label=\"alexnet\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('C:\\\\Users\\\\55019\\\\Desktop\\\\result2\\\\loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "draw_loss(resnet_loss,resnet_loss101,resnet_loss152,vgg_loss,alexnet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7021b1-9464-469a-8a80-371d7be62eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c4dcba-b8af-49c5-ad09-2828ce19e1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsize=128\n",
    "figure=cv2.imread('D:\\\\python\\\\image-sentiment-analysis-master\\\\image\\\\pos\\\\80.jpg')\n",
    "figure=cv2.resize(figure,(fsize,fsize))\n",
    "figure=cv2.cvtColor(figure, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('D:\\\\python\\\\image-sentiment-analysis-master\\\\image\\\\images_resized\\\\1.png',figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15c499-f8f4-4692-8d59-c5781137b209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
